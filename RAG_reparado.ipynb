{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr/Iu8dHaYsF6/GP4WPjkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ailkrobot/RAG-Retrieval-Augmented-Generation/blob/main/RAG_reparado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvQZTrZDUeaD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG ‚Äì Retrieval-Augmented Generation\n",
        "Este es un tutorial para aplicar el concepto de RAG usado para LLMs.\n",
        "\n"
      ],
      "metadata": {
        "id": "kPeuCNowUgPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este c√≥digo es una implementaci√≥n simple de RAG sin LangChain, usando directamente chromadb y sentence-transformers. Vamos l√≠nea por l√≠nea:"
      ],
      "metadata": {
        "id": "uh5ClycxYHaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© Objetivo del c√≥digo:\n",
        "Crear una base de datos vectorial usando ChromaDB y SentenceTransformers, para almacenar frases t√©cnicas con embeddings, y luego poder hacer b√∫squedas sem√°nticas."
      ],
      "metadata": {
        "id": "XflnNAbCYOsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos instalar Chromadb que es una base de datos de vectores open source para almacenar e indexar embeddings"
      ],
      "metadata": {
        "id": "jn5Gxne_YcQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb sentence-transformers\n"
      ],
      "metadata": {
        "id": "g_vTOe8FUtVn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui ya importamos esta Chromadb y Transformes, luego utilizaremos la llamada con clients, utilizamos el modelo predeterminado y enviaremos los textos indicados."
      ],
      "metadata": {
        "id": "loEUM_IdWpe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Importar las dos librer√≠as clave:\n",
        "*   chromadb para almacenar y consultar vectores sem√°nticos.\n",
        "*   SentenceTransformer para generar embeddings de frases.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GJCxboOpYinO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "LO8ZN8XFY0M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Crea un cliente local de ChromaDB (puede correr en memoria o en disco, seg√∫n la configuraci√≥n)."
      ],
      "metadata": {
        "id": "WansjmJ3YoQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.Client()\n"
      ],
      "metadata": {
        "id": "6O2KbCGkY16_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Crea una colecci√≥n de vectores llamada \"docs\", como si fuera una tabla en una base de datos, donde se guardan documentos y sus embeddings."
      ],
      "metadata": {
        "id": "K88uRiNxYwGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = client.create_collection(\"docs\")"
      ],
      "metadata": {
        "id": "AV7VzrmRYh6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga un modelo preentrenado de** HuggingFace** que transforma texto en vectores de forma eficiente (ligero y r√°pido).\n",
        "**\"all-MiniLM-L6-v2\"** es ideal para tareas de recuperaci√≥n sem√°ntica."
      ],
      "metadata": {
        "id": "Y1OPtxcXZHoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "_EmYMRRvZPT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Crea una lista de frases que vamos a almacenar y poder buscar luego.\n",
        "Esto simula que tienes documentos t√©cnicos breves."
      ],
      "metadata": {
        "id": "9pJ-k-SPZbu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"La inteligencia artificial es fascinante.\", \"El control rob√≥tico es crucial.\"]\n"
      ],
      "metadata": {
        "id": "Q7a4kACeZgMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Convierte cada frase en un vector num√©rico (embedding).\n",
        "Este es el paso fundamental para b√∫squeda sem√°ntica: frases similares tendr√°n vectores similares."
      ],
      "metadata": {
        "id": "HASLbkA-ZqCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(texts)"
      ],
      "metadata": {
        "id": "wC0KhziNZ1bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Recorre cada frase:\n",
        "\n",
        "Asigna un id como \"0\", \"1\", etc.\n",
        "Inserta el texto y su embedding en la colecci√≥n de Chroma."
      ],
      "metadata": {
        "id": "Y1SH9yXYZ170"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, text in enumerate(texts):\n",
        "    collection.add(documents=[text], ids=[str(i)], embeddings=[embeddings[i]])"
      ],
      "metadata": {
        "id": "xvUNLCMqZrC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° Esto te deja lista una colecci√≥n vectorial donde luego podr√°s hacer b√∫squedas por similitud, por ejemplo: \"¬øD√≥nde se habla de rob√≥tica?\" y obtener \"El control rob√≥tico es crucial.\"."
      ],
      "metadata": {
        "id": "9gzznYLkaKUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EL programa completo lo puedes ver asi:"
      ],
      "metadata": {
        "id": "s_G2RbDZaSHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"docs\")\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "texts = [\"La inteligencia artificial es fascinante.\", \"El control rob√≥tico es crucial.\"]\n",
        "embeddings = model.encode(texts)\n",
        "\n",
        "for i, text in enumerate(texts):\n",
        "    collection.add(documents=[text], ids=[str(i)], embeddings=[embeddings[i]])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528,
          "referenced_widgets": [
            "ce205b07fad24b9ab0c265f5d4ccb615",
            "4dbfcde7300540bdb0b21399fddc9f72",
            "cdd28812149d40f1b24ea62ae3486279",
            "0374e13d03874150a2d0aac25a2866e5",
            "d847a5afed3144a5ba8248e6a44659ec",
            "312667f7dbc44098878cd7d2a739abd9",
            "f52b4177ba324e03bf2af26bc4a2012c",
            "a5c0a7cb320849d384d6a6728a230c82",
            "b795df97e092452693cfd55851790f80",
            "96d7e3356a1f4ab495a2969efa7c066c",
            "25986f41e9834a95928d8c33d02b4fd7",
            "cf8cb6b34ee9479793a0c18dd099cb8f",
            "a869483541ff41c2821bc634e7d7eee7",
            "3a235124825b4ff1b46a78fc9601b75c",
            "3c7ad9901be544b8935c333e27081622",
            "99d0d88bd022439392f95dbb99159600",
            "11e48eaac7b442fc99c26166362c8fc7",
            "154330b08bd04812b2fa5fc457864d15",
            "fee946fbfb1f4381ba351cf6a09d3b1a",
            "d9fd6367ed85447f8799d3b35fe68155",
            "ab76a7a4ae354911a042ab1e854c02fd",
            "4d6059f3b5e4453c80f7d18b1257af13",
            "e4f0a5751f6e409a9d40dd41c9400dcf",
            "928257b6a1464cf5bb25509f8505ba0f",
            "99605b79e48f4a439c9fdd9b6d594d34",
            "e6a40ea293544b3093dcb0de244741c4",
            "2732906214594419a5e327915a003e90",
            "5cc0936e4fa34561a6ae9d1a020d3f38",
            "ae71e4e83a5b4a47bf8657017c7ccf13",
            "cd17691b58c14dc1ba3059d74764d0dc",
            "85bca56c737744798103fbb8096e53d4",
            "6fbd2c4932ef488491ad94986f0df2d1",
            "91eb989940fe4d31849b0221969d924d",
            "148238dbbdea4f718000471ebc1456ea",
            "1fe38dba703942c7a0671cd644cdf956",
            "859bb5a1885942b7878c949cf3cbf3ff",
            "f83dbcfaf3234f74b756cddca55b770b",
            "5f50c942baaa48fab2fd307f075f9497",
            "ba73291f2d5e4ad6b7a60da8491a783e",
            "180aeb8f5a6345d389a4f05ff675bd43",
            "0ae5c31c3bd944388b8e2a7268039b5a",
            "344fb63fe6494a8e82ad082d7a1517d5",
            "2e76ddca3b83437c8b01b4891d5f6c7a",
            "b36858cb283e4d57a1b48c8b0c222070",
            "589f6ad4a5514885b3f9bd35bcbdd406",
            "c55d5fe38bb046cab0c492a0c3bbe4d5",
            "1ec9b30c9d2a4c64924beccf1d3912a4",
            "77e593d7231448acb78508041c0a1edb",
            "47587ccd8c64492a97a76de719510504",
            "6be20878b1fd4c6ab7ca758d78ce3504",
            "68df31497b6c48e7907bd5f36afc6faa",
            "a762380aea3d40c484c882a5b5c36995",
            "55d9e918407b45d595002c115ca44f73",
            "a8e062908637412292690dc37e047a5a",
            "75ddb32addf34c30b24861d6c9d4fbd2",
            "a1f9af9f6a154ccd9b03d49f25468392",
            "62ba98790b9b464689e75dc17ec5481b",
            "5c469a3605414815b322456902cde0ea",
            "4c43b440ffe84f688566da353f87f7ee",
            "fb74db293de74245bea9d7987b0c7b7b",
            "3f3ef0bdfad64bbca77eb0f95dd3903a",
            "757d1417023641089c5882c80d7a89b3",
            "4525d0088f1c403fbc6568c096415e9c",
            "bf9a4232ff83487bac913b6ee345335b",
            "87a0f364aa414f1593b2eb74eb2b94bb",
            "9258e64c7e7d436f8b9494d24cc7fc4b",
            "c88432e318e64ad4bddafaf78644d4a8",
            "df28ac028eb6457b829b2d7dac59453b",
            "a8dd70efc0d047be80b2c49106f82b19",
            "1e053b96b1f54cc2959436def5a6b3f0",
            "3ad06764ff5e414bb45e10c355bdabe0",
            "e55c724a79ef4195b3604c0d134dfbd7",
            "54950fd9f37a42f7bc3a0cde66194d11",
            "4645f19e8e03496abb4f07b7ef75229a",
            "fad1ba19200042138a34fa268afcf7e0",
            "8dc51c587f4d42e0bd9387ff8e168b36",
            "9208c9a059af4e6c8d9d8cac8e095167",
            "e8a9342c15d24a1cb2cbf4237fbd7c1f",
            "3dd141bde5c147659f230c1458a01810",
            "b4f5ab6cfd8144768eaf639e29735e5c",
            "3043415d5bbc473bbc4e0126691167ca",
            "94279f18a98b4d93a3c089218e3c62c9",
            "bea57d57c39b4e3d945c1ff4c46e1c7f",
            "01b6103077fb4531b6b01eeba95b0350",
            "d0898156894944f4b102877a0c841999",
            "8d4de9d5c26b48e0ba7540b4e62429b3",
            "4813085cc4b74bbbb3d829b2c83ba951",
            "f0494f7adf9d480fade42e001b6fde6f",
            "45a50d40179e46859d26a342e8bea6bb",
            "a447a25ad8f2423797e9d29fae8a6a37",
            "9da0d0111f6048a3b8532ca1c218d19e",
            "95046d5ac2e544b1ab929b9cdb9637fe",
            "d19fa43f22ae4395b2e10cc438c6d84b",
            "b408936ef7ba4efe8c9605a1ca3dc090",
            "15cbf63d1005431bbf14e1cfcb5f7208",
            "33ba023bdce045e6aac106f0b55bc616",
            "e01ef34cab134bdda0375bdbd50b5bf5",
            "16f862731fe441fab9087fa6ddd71742",
            "b395aca73f85427abcaabaa054557943",
            "680de06bfde844f48fd9b2b34d61d169",
            "f8549a62898e444d9afc062794e79098",
            "b5c60df110cb4427901fea4db1233bc6",
            "3b15de9c2ec14b349c0ef4a4653b18f6",
            "9a77af49df1842ad96e4fa2af774e069",
            "b39b31123a3047f1879cb845ae1559d2",
            "324003ba97cd439e9e857fc9c298bfc9",
            "ab727c74241945879c6e07db7b1e2efc",
            "452a966c1f8246799a5d2ff17acb6784",
            "3dc4347d6d5d4fb194ef08709b22f926",
            "006525665fa4483bac3a13c1a203a269",
            "a9c8334f73554e3ea179b182d495a8a3",
            "34eb00185b0b45898430089736aafa2f",
            "aaabc0d776004fe4bb889e46504bc616",
            "137780b530ab41ed97f3565bc793d873",
            "75c9d80fa1af42f3962372a3d3f22c99",
            "9380d83f51f0420f9cf52e1b7969cbb5",
            "6137b9aaf0a34772a664d832b0648f51",
            "eade277accb541d5a113adab1e8f28a9",
            "1e6b524fa1704a099ead84ac3bd60958",
            "626022775de24ef5b0e375070bab792e",
            "1b564bcd727c448681f46f6c5786a84a"
          ]
        },
        "id": "UvsapT3VWmPN",
        "outputId": "d5008c12-269a-42a0-d517-163b34ceee77",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce205b07fad24b9ab0c265f5d4ccb615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8cb6b34ee9479793a0c18dd099cb8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4f0a5751f6e409a9d40dd41c9400dcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "148238dbbdea4f718000471ebc1456ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "589f6ad4a5514885b3f9bd35bcbdd406"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1f9af9f6a154ccd9b03d49f25468392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c88432e318e64ad4bddafaf78644d4a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8a9342c15d24a1cb2cbf4237fbd7c1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45a50d40179e46859d26a342e8bea6bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "680de06bfde844f48fd9b2b34d61d169"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9c8334f73554e3ea179b182d495a8a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego verificaremos con una busqueda deseada o requerimientos necesarios"
      ],
      "metadata": {
        "id": "KG5O9pgFXP0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = model.encode(\"¬øQu√© es el control?\")\n",
        "results = collection.query(query_embeddings=[query], n_results=1)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73KS8tPNXYJw",
        "outputId": "7f0b5b2f-860f-4c03-9b0b-499dcaeabe63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['1']], 'embeddings': None, 'documents': [['El control rob√≥tico es crucial.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[0.5939409732818604]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = model.encode(\"¬øQu√© opinas de la inteligencia artificial?\")\n",
        "results = collection.query(query_embeddings=[query], n_results=1)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlvRsb5PXdt1",
        "outputId": "b1a26165-7721-457a-b34e-e9113d96cdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['0']], 'embeddings': None, 'documents': [['La inteligencia artificial es fascinante.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[0.3903503119945526]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = model.encode(\"¬øQu√© opinas del control?\")\n",
        "results = collection.query(query_embeddings=[query], n_results=1)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCqXUQ8pXqpI",
        "outputId": "6c95bfa5-3322-490b-defb-795dc3d1ca79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': [['1']], 'embeddings': None, 'documents': [['El control rob√≥tico es crucial.']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[0.8778367042541504]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un  CLI (Command Line Interface) que es una interfaz basada en texto que se usa desde la l√≠nea de comandos (terminal o consola), donde t√∫ escribes comandos y el programa responde con texto.\n",
        "$ python buscador.py\n",
        "üëâ Ingresa tu pregunta: ¬øQu√© se dice sobre inteligencia artificial?\n",
        "üîç Resultado: La inteligencia artificial es fascinante.\n",
        "‚úÖ Ventajas de un CLI:\n",
        "‚úÖ R√°pido de desarrollar (ideal para prototipos).\n",
        "\n",
        "‚úÖ Ligero, sin necesidad de interfaz gr√°fica.\n",
        "\n",
        "‚úÖ Perfecto para ejecutar scripts t√©cnicos, pruebas o automatizaciones.\n",
        "üß† En este proyecto RAG:\n",
        "Podemos crear un CLI donde t√∫ escribes preguntas y el sistema busca en tu base de documentaci√≥n t√©cnica (Chroma + embeddings) para darte una respuesta.\n",
        "Aqui un ejemplo funcional de un CLI en Python que hace b√∫squeda sem√°ntica con ChromaDB y sentence-transformers. Este CLI permite consultar frases almacenadas en tu colecci√≥n de documentaci√≥n t√©cnica."
      ],
      "metadata": {
        "id": "w4DsDVDpcT2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ ¬øQu√© hace el siguiente script?\n",
        "\n",
        "\n",
        "Carga tus textos t√©cnicos.\n",
        "\n",
        "-Los convierte en embeddings y los guarda en ChromaDB.\n",
        "\n",
        "-Te permite hacer preguntas desde consola.\n",
        "\n",
        "-Usa sentence-transformers para convertir la pregunta en embedding.\n",
        "\n",
        "-Busca el documento m√°s parecido y te lo muestra.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GYRZqJHec1LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Inicializar cliente y colecci√≥n\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"docs2\")\n",
        "\n",
        "# Modelo de embeddings\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Documentos t√©cnicos que quieres almacenar\n",
        "texts = [\n",
        "    \"La inteligencia artificial es fascinante.\",\n",
        "    \"El control rob√≥tico es crucial.\",\n",
        "    \"Los agentes inteligentes ayudan en la automatizaci√≥n.\",\n",
        "    \"Los sensores son vitales en rob√≥tica.\",\n",
        "    \"Python es ampliamente usado en IA.\"\n",
        "]\n",
        "\n",
        "# Generar embeddings y almacenar en ChromaDB\n",
        "embeddings = model.encode(texts)\n",
        "for i, text in enumerate(texts):\n",
        "    collection.add(documents=[text], ids=[str(i)], embeddings=[embeddings[i]])\n",
        "\n",
        "# üß† CLI interactivo\n",
        "print(\"üîç Buscador inteligente de documentaci√≥n t√©cnica\")\n",
        "print(\"Escribe tu pregunta (o 'salir' para terminar):\\n\")\n",
        "\n",
        "while True:\n",
        "    pregunta = input(\"üëâ Tu pregunta: \")\n",
        "    if pregunta.lower() in [\"salir\", \"exit\", \"q\"]:\n",
        "        print(\"üëã ¬°Hasta luego!\")\n",
        "        break\n",
        "\n",
        "    query_embedding = model.encode(pregunta)\n",
        "    resultado = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
        "\n",
        "    print(\"\\nüß† Resultado m√°s relevante:\")\n",
        "    print(f\"üìÑ {resultado['documents'][0][0]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jABQhdTAbfN0",
        "outputId": "41b86ac9-89d2-414c-8bc8-c321145d7ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Buscador inteligente de documentaci√≥n t√©cnica\n",
            "Escribe tu pregunta (o 'salir' para terminar):\n",
            "\n",
            "üëâ Tu pregunta: que sabes de python\n",
            "\n",
            "üß† Resultado m√°s relevante:\n",
            "üìÑ Python es ampliamente usado en IA.\n",
            "\n",
            "üëâ Tu pregunta: que sabes de IA\n",
            "\n",
            "üß† Resultado m√°s relevante:\n",
            "üìÑ Python es ampliamente usado en IA.\n",
            "\n",
            "üëâ Tu pregunta: y que sobre sensores\n",
            "\n",
            "üß† Resultado m√°s relevante:\n",
            "üìÑ Los sensores son vitales en rob√≥tica.\n",
            "\n",
            "üëâ Tu pregunta: salir\n",
            "üëã ¬°Hasta luego!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui el programa consigue leer desde un archivo.\n",
        "\n",
        "üìÅ Paso 1: **Prepara tu archivo**\n",
        "\n",
        "**Crea un archivo llamado por ejemplo:**\n",
        "\n",
        "docs/tecnologia.txt\n",
        "(con contenido como este):\n",
        "\n",
        "-La inteligencia artificial est√° revolucionando muchas industrias.\n",
        "\n",
        "-El control rob√≥tico se usa en f√°bricas automatizadas.\n",
        "\n",
        "-Los sensores permiten que los robots perciban su entorno.\n",
        "\n",
        "-El lenguaje Python es muy popular para programaci√≥n en IA.\n",
        "\n",
        "‚ñ∂Ô∏è **¬øC√≥mo ejecutarlo?**\n",
        "\n",
        "Aseg√∫rate de tener esta estructura:\n",
        "\n",
        "Copiar\n",
        "\n",
        "Editar\n",
        "\n",
        "üìÇ proyecto/\n",
        "\n",
        "‚îú‚îÄ buscador.py\n",
        "\n",
        "‚îî‚îÄ docs/\n",
        "\n",
        "    ‚îî‚îÄ tecnologia.txt\n",
        "    \n",
        "Ejecuta con:\n",
        "\n",
        "python buscador.py\n",
        "\n"
      ],
      "metadata": {
        "id": "DcUAVblkeSDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 1. Leer el archivo de texto\n",
        "def cargar_textos(ruta_archivo):\n",
        "    with open(ruta_archivo, \"r\", encoding=\"utf-8\") as f:\n",
        "        lineas = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    return lineas\n",
        "\n",
        "# 2. Inicializar cliente y colecci√≥n\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"docs\")\n",
        "\n",
        "# 3. Cargar textos desde archivo\n",
        "ruta = \"docs/tecnologia.txt\"\n",
        "textos = cargar_textos(ruta)\n",
        "\n",
        "# 4. Embeddings con modelo\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(textos)\n",
        "\n",
        "# 5. Insertar en Chroma\n",
        "for i, texto in enumerate(textos):\n",
        "    collection.add(documents=[texto], ids=[str(i)], embeddings=[embeddings[i]])\n",
        "\n",
        "# 6. CLI interactivo\n",
        "print(\"üîç Buscador de documentaci√≥n t√©cnica\")\n",
        "print(\"Escribe tu pregunta (o 'salir'):\\n\")\n",
        "\n",
        "while True:\n",
        "    pregunta = input(\"üëâ Tu pregunta: \")\n",
        "    if pregunta.lower() in [\"salir\", \"exit\", \"q\"]:\n",
        "        print(\"üëã ¬°Hasta luego!\")\n",
        "        break\n",
        "\n",
        "    query_embedding = model.encode(pregunta)\n",
        "    resultado = collection.query(query_embeddings=[query_embedding], n_results=1)\n",
        "\n",
        "    print(\"\\nüß† Resultado m√°s relevante:\")\n",
        "    print(f\"üìÑ {resultado['documents'][0][0]}\\n\")\n"
      ],
      "metadata": {
        "id": "XgSoZyPteTyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Este CLI ahora te permite:\n",
        "\n",
        "-Leer un archivo con frases o p√°rrafos t√©cnicos.\n",
        "\n",
        "-Almacenar y vectorizar el contenido.\n",
        "\n",
        "-Consultar sem√°nticamente desde terminal"
      ],
      "metadata": {
        "id": "WbnTTjcSe3at"
      }
    }
  ]
}